# ðŸš€ Guia Completo de Deploy no Streamlit Cloud

## ðŸ“Š VisÃ£o Geral

Este guia mostra **3 formas diferentes** de carregar dados automaticamente no Streamlit Cloud.

---

## ðŸŽ¯ MÃ©todo 1: Pasta Local (Arquivos pequenos < 100MB)

### âœ… Melhor para:
- Arquivos CSV pequenos e mÃ©dios
- Dados que nÃ£o mudam frequentemente
- Simplicidade mÃ¡xima

### ðŸ“ Estrutura do Projeto:

```
meu-projeto/
â”œâ”€â”€ app.py                 # CÃ³digo principal
â”œâ”€â”€ requirements.txt       # DependÃªncias
â”œâ”€â”€ .gitignore            # (opcional)
â””â”€â”€ data/                 # â† Seus CSVs aqui
    â”œâ”€â”€ patrimonio1.csv
    â”œâ”€â”€ patrimonio2.csv
    â””â”€â”€ patrimonio3.csv
```

### ðŸ”§ Passos:

1. **Criar estrutura de pastas:**
```bash
mkdir data
cp seus_arquivos/*.csv data/
```

2. **Criar `.gitignore` (opcional, se arquivos muito grandes):**
```
# .gitignore
*.pyc
__pycache__/
.DS_Store
```

3. **Criar `requirements.txt`:**
```
streamlit>=1.28.0
pandas>=2.0.0
numpy>=1.24.0
plotly>=5.17.0
openpyxl>=3.1.0
xlsxwriter>=3.1.0
```

4. **Fazer commit:**
```bash
git add .
git commit -m "Deploy inicial com dados"
git push origin main
```

5. **No Streamlit Cloud:**
   - Acesse: https://share.streamlit.io
   - Conecte seu repositÃ³rio GitHub
   - A app carregarÃ¡ automaticamente da pasta `data/`

---

## ðŸŒ MÃ©todo 2: URLs Remotas (RECOMENDADO para arquivos grandes)

### âœ… Melhor para:
- Arquivos > 100MB
- Dados que mudam periodicamente
- MÃºltiplas fontes de dados
- NÃ£o sobrecarregar o repositÃ³rio Git

### ðŸ“ Estrutura do Projeto:

```
meu-projeto/
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py             # â† ConfiguraÃ§Ã£o de URLs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### ðŸ”§ Passos:

#### A) Usando GitHub (arquivos atÃ© 100MB)

1. **Criar repositÃ³rio separado para dados** (opcional mas recomendado):
```
dados-patrimonio/
â””â”€â”€ csvs/
    â”œâ”€â”€ arquivo1.csv
    â”œâ”€â”€ arquivo2.csv
    â””â”€â”€ arquivo3.csv
```

2. **Obter URLs raw do GitHub:**
   - Navegue atÃ© o arquivo no GitHub
   - Clique em "Raw"
   - Copie a URL (formato: `https://raw.githubusercontent.com/usuario/repo/main/csvs/arquivo1.csv`)

3. **Configurar `config.py`:**
```python
CSV_URLS = [
    "https://raw.githubusercontent.com/usuario/dados-patrimonio/main/csvs/arquivo1.csv",
    "https://raw.githubusercontent.com/usuario/dados-patrimonio/main/csvs/arquivo2.csv",
]

AUTO_LOAD = True
CACHE_DURATION = 3600
```

#### B) Usando Google Drive (qualquer tamanho)

1. **Preparar arquivos no Google Drive:**
   - FaÃ§a upload dos CSVs para o Google Drive
   - Clique com botÃ£o direito no arquivo
   - Selecione "Compartilhar"
   - Altere para "Qualquer pessoa com o link"
   - Copie o link

2. **Extrair ID do arquivo:**
   - URL original: `https://drive.google.com/file/d/1ABC123XYZ789/view?usp=sharing`
   - ID: `1ABC123XYZ789`

3. **Configurar `config.py`:**
```python
GOOGLE_DRIVE_FILES = [
    "https://drive.google.com/file/d/1ABC123XYZ789/view",
    "https://drive.google.com/file/d/1DEF456UVW012/view",
]

DATA_URLS = GOOGLE_DRIVE_FILES
AUTO_LOAD = True
CACHE_DURATION = 3600
```

#### C) Usando Dropbox

1. **Preparar no Dropbox:**
   - FaÃ§a upload dos arquivos
   - Clique em "Compartilhar"
   - Crie link pÃºblico
   - **IMPORTANTE**: Mude `dl=0` para `dl=1` no final da URL

2. **Configurar `config.py`:**
```python
DROPBOX_FILES = [
    "https://www.dropbox.com/s/codigo123/arquivo1.csv?dl=1",
    "https://www.dropbox.com/s/codigo456/arquivo2.csv?dl=1",
]

DATA_URLS = DROPBOX_FILES
AUTO_LOAD = True
```

---

## ðŸ” MÃ©todo 3: Streamlit Secrets (Dados SensÃ­veis)

### âœ… Melhor para:
- URLs privadas/sensÃ­veis
- Credenciais de acesso
- MÃ¡xima seguranÃ§a

### ðŸ”§ Passos:

1. **No Streamlit Cloud:**
   - VÃ¡ em Settings â†’ Secrets
   - Adicione as URLs:

```toml
[data]
csv_urls = [
    "https://storage.example.com/private/arquivo1.csv?token=abc123",
    "https://storage.example.com/private/arquivo2.csv?token=xyz789"
]
```

2. **Modificar cÃ³digo para ler secrets:**
```python
# No inÃ­cio do app.py
try:
    DATA_URLS = st.secrets["data"]["csv_urls"]
except:
    DATA_URLS = []
```

---

## ðŸŽ›ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Cache para Performance

Adicione caching para evitar recarregar dados a cada interaÃ§Ã£o:

```python
@st.cache_data(ttl=3600)  # Cache por 1 hora
def load_cached_data(urls):
    analyzer = PatrimonioAnalyzer()
    analyzer.load_data_from_url(urls)
    analyzer.preprocess_data()
    return analyzer.data
```

### AtualizaÃ§Ã£o AutomÃ¡tica

Para dados que mudam frequentemente, configure refresh automÃ¡tico:

```python
# config.py
AUTO_LOAD = True
CACHE_DURATION = 1800  # 30 minutos
AUTO_REFRESH = True
```

---

## ðŸ› Troubleshooting

### Problema: "FileNotFoundError: data/"
**SoluÃ§Ã£o**: Certifique-se que a pasta `data/` estÃ¡ commitada no Git
```bash
git add data/
git commit -m "Adiciona pasta data"
```

### Problema: "403 Forbidden" ao carregar do Google Drive
**SoluÃ§Ã£o**: Verifique se o arquivo estÃ¡ configurado como "Qualquer pessoa com o link"

### Problema: Dados nÃ£o carregam automaticamente
**SoluÃ§Ã£o**: Verifique se `AUTO_LOAD = True` no `config.py`

### Problema: Arquivos muito grandes (> 1GB)
**SoluÃ§Ã£o**: 
- Use Google Drive ou serviÃ§o de cloud storage
- Considere comprimir os arquivos
- Divida em arquivos menores

### Problema: Encoding errado (caracteres estranhos)
**SoluÃ§Ã£o**: O cÃ³digo jÃ¡ tenta utf-8 e latin-1 automaticamente. Se persistir:
```python
df = pd.read_csv(file, encoding='cp1252')  # Windows
# ou
df = pd.read_csv(file, encoding='iso-8859-1')  # Latin
```

---

## ðŸ“ˆ Melhores PrÃ¡ticas

### âœ… DO:
- Use URLs para arquivos grandes (>100MB)
- Configure cache adequado
- Mantenha dados separados do cÃ³digo
- Use `.gitignore` para arquivos locais grandes
- Documente as fontes dos dados

### âŒ DON'T:
- NÃ£o commite arquivos > 100MB no Git
- NÃ£o hardcode credenciais no cÃ³digo
- NÃ£o desabilite cache sem necessidade
- NÃ£o ignore tratamento de erros

---

## ðŸš¦ Checklist de Deploy

- [ ] Escolher mÃ©todo de carregamento adequado
- [ ] Criar `requirements.txt` com todas dependÃªncias
- [ ] Testar localmente: `streamlit run app.py`
- [ ] Verificar encoding dos CSVs
- [ ] Configurar URLs ou pasta `data/`
- [ ] Fazer commit e push
- [ ] Conectar no Streamlit Cloud
- [ ] Testar carregamento automÃ¡tico
- [ ] Verificar logs de erro no dashboard
- [ ] Configurar cache apropriado

---

## ðŸ“ž Suporte

- **Streamlit Docs**: https://docs.streamlit.io
- **Community Forum**: https://discuss.streamlit.io
- **GitHub Issues**: Crie issue no seu repositÃ³rio

---

## ðŸŽ“ Exemplo Completo

### Estrutura Final Recomendada:

```
patrimonio-app/
â”‚
â”œâ”€â”€ app.py                      # AplicaÃ§Ã£o principal
â”œâ”€â”€ config.py                   # ConfiguraÃ§Ãµes (URLs, etc)
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ DEPLOY_GUIDE.md            # Este guia
â”‚
â”œâ”€â”€ .gitignore                 # Ignorar arquivos desnecessÃ¡rios
â”‚
â””â”€â”€ data/                      # (Opcional) CSVs locais
    â””â”€â”€ .gitkeep               # Manter pasta vazia no Git
```

### `.gitignore` sugerido:
```
# Python
__pycache__/
*.py[cod]
*$py.class
.Python

# Streamlit
.streamlit/

# Data (se usar URLs)
data/*.csv
!data/.gitkeep

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db
```

---

## ðŸŽ‰ Pronto!

Sua aplicaÃ§Ã£o agora estÃ¡ configurada para carregar dados automaticamente no Streamlit Cloud!

**URL tÃ­pica**: `https://usuario-patrimonio-app.streamlit.app`