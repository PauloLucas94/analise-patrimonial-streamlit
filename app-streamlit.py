import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, date
import re
from io import BytesIO
import base64
import os
from pathlib import Path

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise de Patrim√¥nio",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

class PatrimonioAnalyzer:
    def __init__(self):
        self.data = None
        self.processed = False
    
    def load_data_from_folder(self, folder_path='data'):
        """Carrega automaticamente todos os CSVs de uma pasta"""
        dataframes = []
        folder = Path(folder_path)
        
        if not folder.exists():
            st.warning(f"‚ö†Ô∏è Pasta '{folder_path}' n√£o encontrada. Criando pasta...")
            folder.mkdir(exist_ok=True)
            return False
        
        csv_files = list(folder.glob('*.csv'))
        
        if not csv_files:
            st.warning(f"‚ö†Ô∏è Nenhum arquivo CSV encontrado em '{folder_path}'")
            return False
        
        st.info(f"üìÇ Carregando {len(csv_files)} arquivo(s) CSV da pasta '{folder_path}'...")
        
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8')
                df['arquivo_origem'] = csv_file.name
                dataframes.append(df)
                st.success(f"‚úì {csv_file.name}: {len(df)} registros carregados")
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(csv_file, encoding='latin-1')
                    df['arquivo_origem'] = csv_file.name
                    dataframes.append(df)
                    st.success(f"‚úì {csv_file.name}: {len(df)} registros carregados (latin-1)")
                except Exception as e:
                    st.error(f"‚úó Erro ao carregar {csv_file.name}: {str(e)}")
            except Exception as e:
                st.error(f"‚úó Erro ao carregar {csv_file.name}: {str(e)}")
        
        if dataframes:
            self.data = pd.concat(dataframes, ignore_index=True)
            return True
        return False
    
    def load_data_from_upload(self, uploaded_files):
        """Carrega dados dos arquivos CSV enviados via upload"""
        dataframes = []
        
        for uploaded_file in uploaded_files:
            try:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
                df['arquivo_origem'] = uploaded_file.name
                dataframes.append(df)
                st.success(f"‚úì {uploaded_file.name}: {len(df)} registros carregados")
            except Exception as e:
                st.error(f"‚úó Erro ao carregar {uploaded_file.name}: {str(e)}")
        
        if dataframes:
            self.data = pd.concat(dataframes, ignore_index=True)
            return True
        return False
    
    def load_data_from_url(self, urls):
        """Carrega dados de URLs (GitHub, Google Drive, etc)"""
        dataframes = []
        
        for url in urls:
            try:
                if 'drive.google.com' in url:
                    file_id = url.split('/d/')[1].split('/')[0]
                    url = f'https://drive.google.com/uc?id={file_id}'
                
                df = pd.read_csv(url)
                df['arquivo_origem'] = f"URL_{len(dataframes)+1}"
                dataframes.append(df)
                st.success(f"‚úì URL {len(dataframes)}: {len(df)} registros carregados")
            except Exception as e:
                st.error(f"‚úó Erro ao carregar URL: {str(e)}")
        
        if dataframes:
            self.data = pd.concat(dataframes, ignore_index=True)
            return True
        return False
    
    def preprocess_data(self):
        """Preprocessa os dados"""
        if self.data is None:
            return False
        
        self.data.columns = self.data.columns.str.strip()
        
        if 'Data Incorpora√ß√£o' in self.data.columns:
            self.data['Data Incorpora√ß√£o'] = pd.to_datetime(self.data['Data Incorpora√ß√£o'], errors='coerce')
            self.data['Ano Incorpora√ß√£o'] = self.data['Data Incorpora√ß√£o'].dt.year
            # Calcula idade dos itens
            self.data['Idade_Item'] = 2025 - self.data['Ano Incorpora√ß√£o']
        
        if 'Percentagem de Similaridade (%)' in self.data.columns:
            self.data['Similaridade_Num'] = pd.to_numeric(
                self.data['Percentagem de Similaridade (%)'].str.replace('%', ''), 
                errors='coerce'
            )
        
        if 'Valor Aquisi√ß√£o' in self.data.columns:
            self.data['Valor_Aquisicao_Num'] = pd.to_numeric(
                self.data['Valor Aquisi√ß√£o'].str.replace('R$', '').str.replace('.', '').str.replace(',', '.').str.strip(),
                errors='coerce'
            )
        
        if 'Valor Cont√°bil' in self.data.columns:
            self.data['Valor_Contabil_Num'] = pd.to_numeric(
                self.data['Valor Cont√°bil'].str.replace('R$', '').str.replace('.', '').str.replace(',', '.').str.strip(),
                errors='coerce'
            )
        
        if 'Vida' in self.data.columns:
            self.data['Vida_Num'] = pd.to_numeric(self.data['Vida'], errors='coerce')
        
        if 'Justificativa de Reprova' in self.data.columns:
            self.data['Decisao'] = self.data['Justificativa de Reprova'].apply(self._categorizar_decisao)
            self.data['Categoria_Similaridade'] = self.data['Similaridade_Num'].apply(self._categorizar_similaridade)
        
        if 'Localiza√ß√£o' in self.data.columns:
            self.data['Regiao'] = self.data['Localiza√ß√£o'].apply(self._extrair_regiao)
        
        self.processed = True
        return True
    
    def _categorizar_decisao(self, justificativa):
        if pd.isna(justificativa):
            return "Sem Categoria"
        
        justificativa = str(justificativa).upper()
        
        if "RECLASSIFICAR" in justificativa:
            return "RECLASSIFICAR"
        elif "AVALIAR" in justificativa:
            return "AVALIAR"
        elif "MANTER" in justificativa:
            return "MANTER"
        else:
            return "OUTROS"
    
    def _categorizar_similaridade(self, similaridade):
        if pd.isna(similaridade):
            return "Sem Dados"
        
        if similaridade >= 70:
            return "Muito Alta (‚â•70%)"
        elif similaridade >= 50:
            return "Alta (50-69%)"
        elif similaridade >= 35:
            return "Moderada (35-49%)"
        else:
            return "Baixa (<35%)"
    
    def _extrair_regiao(self, localizacao):
        if pd.isna(localizacao):
            return "N√£o Informado"
        
        return str(localizacao).strip()
    
    def get_filtered_data(self, regiao_filter=None, decisao_filter=None, 
                         ano_min=None, ano_max=None, similaridade_min=None):
        """Retorna dados filtrados"""
        if not self.processed:
            return pd.DataFrame()
        
        filtered = self.data.copy()
        
        if regiao_filter and regiao_filter != "Todas":
            filtered = filtered[filtered['Regiao'] == regiao_filter]
        
        if decisao_filter and decisao_filter != "Todas":
            filtered = filtered[filtered['Decisao'] == decisao_filter]
        
        if ano_min is not None:
            filtered = filtered[filtered['Ano Incorpora√ß√£o'] >= ano_min]
        
        if ano_max is not None:
            filtered = filtered[filtered['Ano Incorpora√ß√£o'] <= ano_max]
        
        if similaridade_min is not None:
            filtered = filtered[filtered['Similaridade_Num'] >= similaridade_min]
        
        return filtered

def create_decision_pie_chart(data):
    """Gr√°fico de pizza das decis√µes"""
    decisoes = data['Decisao'].value_counts()
    
    fig = px.pie(
        values=decisoes.values, 
        names=decisoes.index,
        title="Distribui√ß√£o de Decis√µes",
        color_discrete_sequence=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    )
    
    fig.update_traces(textposition='inside', textinfo='percent+label')
    return fig

def create_similarity_histogram(data):
    """Histograma de similaridade"""
    fig = px.histogram(
        data, 
        x='Similaridade_Num',
        nbins=20,
        title="Distribui√ß√£o de Similaridade (%)",
        labels={'Similaridade_Num': 'Similaridade (%)', 'count': 'Quantidade'}
    )
    
    fig.update_layout(showlegend=False)
    return fig

def create_regional_bar_chart(data):
    """Gr√°fico de barras por localiza√ß√£o"""
    localizacao_counts = data['Regiao'].value_counts()
    
    fig = px.bar(
        x=localizacao_counts.index,
        y=localizacao_counts.values,
        title="Itens por Localiza√ß√£o",
        labels={'x': 'Localiza√ß√£o', 'y': 'Quantidade'}
    )
    
    fig.update_layout(
        showlegend=False,
        xaxis=dict(tickangle=45)
    )
    return fig

def create_similarity_box_plot(data):
    """Box plot de similaridade por decis√£o"""
    fig = px.box(
        data,
        x='Decisao',
        y='Similaridade_Num',
        title="Similaridade por Tipo de Decis√£o",
        labels={'Similaridade_Num': 'Similaridade (%)', 'Decisao': 'Decis√£o'}
    )
    
    return fig

def create_timeline_chart(data):
    """Gr√°fico temporal"""
    timeline = data.groupby(['Ano Incorpora√ß√£o', 'Decisao']).size().unstack(fill_value=0)
    
    fig = go.Figure()
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
    
    for i, decisao in enumerate(timeline.columns):
        fig.add_trace(
            go.Scatter(
                x=timeline.index,
                y=timeline[decisao],
                mode='lines+markers',
                name=decisao,
                line=dict(color=colors[i % len(colors)])
            )
        )
    
    fig.update_layout(
        title="Timeline de Incorpora√ß√µes por Decis√£o",
        xaxis_title="Ano",
        yaxis_title="Quantidade",
        hovermode='x unified'
    )
    
    return fig

def create_strategic_metrics(data):
    """M√©tricas estrat√©gicas"""
    total_itens = len(data)
    
    if total_itens == 0:
        return {}, {}
    
    decisoes = data['Decisao'].value_counts()
    reclassificar = decisoes.get('RECLASSIFICAR', 0)
    avaliar = decisoes.get('AVALIAR', 0)
    manter = decisoes.get('MANTER', 0)
    
    similaridade_stats = data['Similaridade_Num'].describe()
    
    # Calcula idade m√©dia dos itens
    idade_media = data['Idade_Item'].mean() if 'Idade_Item' in data.columns else 0
    
    metrics = {
        'total_itens': total_itens,
        'reclassificar': reclassificar,
        'avaliar': avaliar,
        'manter': manter,
        'percentual_reclassificar': (reclassificar / total_itens) * 100,
        'percentual_avaliar': (avaliar / total_itens) * 100,
        'similaridade_media': similaridade_stats.get('mean', 0),
        'alta_similaridade': len(data[data['Similaridade_Num'] >= 70]),
        'idade_media': idade_media
    }
    
    regional_analysis = data.groupby('Regiao').agg({
        'Decisao': lambda x: (x == 'RECLASSIFICAR').sum(),
        'Similaridade_Num': 'mean'
    }).round(2)
    
    regional_analysis.columns = ['Itens_Reclassificar', 'Similaridade_Media']
    
    return metrics, regional_analysis

def export_to_excel(data):
    """Exporta dados para Excel"""
    output = BytesIO()
    
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        data.to_excel(writer, sheet_name='Dados_Completos', index=False)
        
        decisao_summary = data.groupby('Decisao').agg({
            'Similaridade_Num': ['count', 'mean', 'min', 'max'],
            'Ano Incorpora√ß√£o': ['min', 'max']
        }).round(2)
        decisao_summary.to_excel(writer, sheet_name='Resumo_Decisoes')
        
        regional_summary = data.groupby('Regiao').agg({
            'Decisao': lambda x: x.value_counts().to_dict(),
            'Similaridade_Num': ['count', 'mean']
        })
        regional_summary.to_excel(writer, sheet_name='Resumo_Regional')
    
    return output.getvalue()

def create_demo_data():
    """Cria dados de demonstra√ß√£o"""
    np.random.seed(42)
    n_samples = 1000
    
    sample_data = {
        'Localiza√ß√£o': np.random.choice(['1.01 BR√ÅS', '1.02 VILA ALPINA', '2.01 SANTOS', 'SENAI SEDE', '3.01 TAUBAT√â'], n_samples),
        'Invent√°rio': range(1000000, 1000000 + n_samples),
        'Denomina√ß√£o do Imobilizado': [f"EQUIPAMENTO TESTE {i}" for i in range(n_samples)],
        'Vida': np.random.choice([10, 15, 20, 25, 50], n_samples),
        'Valor Aquisi√ß√£o': [f"R$ {np.random.uniform(100, 50000):.2f}".replace('.', ',') for _ in range(n_samples)],
        'Valor Cont√°bil': [f"R$ {np.random.uniform(0, 30000):.2f}".replace('.', ',') for _ in range(n_samples)],
        'Item Consum√≠vel Similar': [f"CONSUM√çVEL SIMILAR {i}" for i in range(n_samples)],
        'Percentagem de Similaridade (%)': [f"{np.random.uniform(20, 85):.1f}%" for _ in range(n_samples)],
        'Data Incorpora√ß√£o': pd.date_range('2010-01-01', '2025-01-01', periods=n_samples),
        'Justificativa de Reprova': np.random.choice([
            'RECLASSIFICAR: Alta similaridade (70%+)',
            'AVALIAR: Similaridade moderada (45%)',
            'MANTER: Similaridade baixa (25%)'
        ], n_samples, p=[0.25, 0.45, 0.3])
    }
    
    return pd.DataFrame(sample_data)

def main():
    st.title("üìä Sistema de An√°lise de Patrim√¥nio")
    st.markdown("---")
    
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = PatrimonioAnalyzer()
    
    analyzer = st.session_state.analyzer
    
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√£o de Dados")
        
        load_mode = st.radio(
            "Modo de Carregamento:",
            ["üóÇÔ∏è Pasta Local (Auto)", "üì§ Upload Manual", "üîó URLs Remotas", "üéØ Demonstra√ß√£o"],
            help="Escolha como carregar os dados"
        )
        
        st.markdown("---")
        
        if load_mode == "üóÇÔ∏è Pasta Local (Auto)":
            st.info("üìÇ Carregamento autom√°tico da pasta 'data/'")
            
            folder_path = st.text_input("Caminho da pasta:", value="data")
            
            if st.button("üîÑ Carregar Dados"):
                with st.spinner("Carregando arquivos..."):
                    if analyzer.load_data_from_folder(folder_path):
                        if analyzer.preprocess_data():
                            st.success(f"‚úì {len(analyzer.data)} registros carregados!")
                        else:
                            st.error("Erro no processamento dos dados")
            
            if not analyzer.processed and 'auto_loaded' not in st.session_state:
                with st.spinner("Carregando dados automaticamente..."):
                    if analyzer.load_data_from_folder(folder_path):
                        if analyzer.preprocess_data():
                            st.success(f"‚úì {len(analyzer.data)} registros carregados automaticamente!")
                            st.session_state.auto_loaded = True
        
        elif load_mode == "üì§ Upload Manual":
            uploaded_files = st.file_uploader(
                "Selecione os arquivos CSV",
                type=['csv'],
                accept_multiple_files=True,
                help="Voc√™ pode selecionar at√© 12 arquivos CSV"
            )
            
            if uploaded_files:
                if st.button("üì• Carregar Arquivos"):
                    with st.spinner("Carregando arquivos..."):
                        if analyzer.load_data_from_upload(uploaded_files):
                            if analyzer.preprocess_data():
                                st.success(f"‚úì {len(analyzer.data)} registros carregados!")
                            else:
                                st.error("Erro no processamento dos dados")
        
        elif load_mode == "üîó URLs Remotas":
            st.info("üí° Suporta GitHub Raw, Google Drive p√∫blico, etc.")
            
            url_input = st.text_area(
                "URLs (uma por linha):",
                help="Cole as URLs dos arquivos CSV, uma por linha"
            )
            
            if st.button("üåê Carregar de URLs"):
                urls = [url.strip() for url in url_input.split('\n') if url.strip()]
                if urls:
                    with st.spinner("Baixando arquivos..."):
                        if analyzer.load_data_from_url(urls):
                            if analyzer.preprocess_data():
                                st.success(f"‚úì {len(analyzer.data)} registros carregados!")
                            else:
                                st.error("Erro no processamento dos dados")
        
        else:
            if st.button("üéØ Gerar Dados de Demonstra√ß√£o"):
                with st.spinner("Criando dados de demonstra√ß√£o..."):
                    analyzer.data = create_demo_data()
                    analyzer.preprocess_data()
                    st.success("‚úì Dados de demonstra√ß√£o carregados!")
    
    if not analyzer.processed:
        st.info("üëÜ Configure o modo de carregamento na barra lateral para come√ßar")
        
        with st.expander("üìñ Como usar cada modo"):
            st.markdown("""
            ### üóÇÔ∏è Pasta Local (Auto)
            - **Para Streamlit Cloud**: Crie uma pasta `data/` no seu reposit√≥rio
            - Coloque seus arquivos CSV dentro dessa pasta
            - Os dados ser√£o carregados automaticamente no deploy
            
            ### üì§ Upload Manual
            - Use para testes locais ou dados tempor√°rios
            - Arraste e solte seus CSVs
            
            ### üîó URLs Remotas
            - **GitHub**: Use URL raw (ex: `https://raw.githubusercontent.com/user/repo/main/data.csv`)
            - **Google Drive**: Compartilhe o arquivo publicamente e use o link
            - **Outros**: Qualquer URL p√∫blica de CSV
            
            ### üéØ Demonstra√ß√£o
            - Gera 1000 registros de exemplo para testar a aplica√ß√£o
            """)
        
        return
    
    with st.sidebar:
        st.markdown("---")
        st.header("üîß Filtros")
        
        localizacoes = ["Todas"] + sorted(analyzer.data['Regiao'].unique().tolist())
        regiao_filter = st.selectbox("Localiza√ß√£o", localizacoes)
        
        decisoes = ["Todas"] + sorted(analyzer.data['Decisao'].unique().tolist())
        decisao_filter = st.selectbox("Decis√£o", decisoes)
        
        anos = analyzer.data['Ano Incorpora√ß√£o'].dropna()
        if len(anos) > 0:
            ano_min, ano_max = st.slider(
                "Per√≠odo de Incorpora√ß√£o",
                int(anos.min()),
                int(anos.max()),
                (int(anos.min()), int(anos.max()))
            )
        else:
            ano_min, ano_max = None, None
        
        similaridade_min = st.slider(
            "Similaridade M√≠nima (%)",
            0, 100, 0
        )
        
        filtered_data = analyzer.get_filtered_data(
            regiao_filter, decisao_filter, ano_min, ano_max, similaridade_min
        )
    
    st.header("üìà Resumo Executivo")
    
    metrics, regional_analysis = create_strategic_metrics(filtered_data)
    
    if metrics:
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric(
                "Total de Itens",
                f"{metrics['total_itens']:,}",
                help="N√∫mero total de itens na an√°lise"
            )
        
        with col2:
            st.metric(
                "Para Reclassificar",
                f"{metrics['reclassificar']:,}",
                f"{metrics['percentual_reclassificar']:.1f}%",
                help="Itens recomendados para reclassifica√ß√£o"
            )
        
        with col3:
            st.metric(
                "Para Avaliar",
                f"{metrics['avaliar']:,}",
                f"{metrics['percentual_avaliar']:.1f}%",
                help="Itens que necessitam avalia√ß√£o adicional"
            )
        
        with col4:
            st.metric(
                "Similaridade M√©dia",
                f"{metrics['similaridade_media']:.1f}%",
                help="Percentual m√©dio de similaridade com consum√≠veis"
            )
        
        with col5:
            st.metric(
                "Idade M√©dia",
                f"{metrics['idade_media']:.1f} anos",
                help="Idade m√©dia dos itens patrimoniais (2025 - Ano de Incorpora√ß√£o)"
            )
    
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Vis√£o Geral", "üîç An√°lise Detalhada", "üè¢ An√°lise por Localiza√ß√£o", "üìã Dados e Export"])
    
    with tab1:
        st.subheader("Vis√£o Geral dos Dados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_pie = create_decision_pie_chart(filtered_data)
            st.plotly_chart(fig_pie, use_container_width=True)
            
            fig_hist = create_similarity_histogram(filtered_data)
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            fig_bar = create_regional_bar_chart(filtered_data)
            st.plotly_chart(fig_bar, use_container_width=True)
            
            fig_box = create_similarity_box_plot(filtered_data)
            st.plotly_chart(fig_box, use_container_width=True)
    
    with tab2:
        st.subheader("An√°lise Detalhada")
        
        fig_timeline = create_timeline_chart(filtered_data)
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        # An√°lise de Idade por Decis√£o
        st.subheader("üìÖ An√°lise de Idade dos Itens")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'Idade_Item' in filtered_data.columns:
                idade_reclassificar = filtered_data[filtered_data['Decisao'] == 'RECLASSIFICAR']['Idade_Item'].mean()
                st.metric(
                    "Idade M√©dia - RECLASSIFICAR",
                    f"{idade_reclassificar:.1f} anos",
                    help="Idade m√©dia dos itens para reclassificar"
                )
        
        with col2:
            if 'Idade_Item' in filtered_data.columns:
                idade_avaliar = filtered_data[filtered_data['Decisao'] == 'AVALIAR']['Idade_Item'].mean()
                st.metric(
                    "Idade M√©dia - AVALIAR",
                    f"{idade_avaliar:.1f} anos",
                    help="Idade m√©dia dos itens para avaliar"
                )
        
        with col3:
            if 'Idade_Item' in filtered_data.columns:
                idade_manter = filtered_data[filtered_data['Decisao'] == 'MANTER']['Idade_Item'].mean()
                st.metric(
                    "Idade M√©dia - MANTER",
                    f"{idade_manter:.1f} anos",
                    help="Idade m√©dia dos itens para manter"
                )
        
        # Box plot de idade por decis√£o
        if 'Idade_Item' in filtered_data.columns:
            fig_idade = px.box(
                filtered_data,
                x='Decisao',
                y='Idade_Item',
                title="Distribui√ß√£o de Idade por Tipo de Decis√£o",
                labels={'Idade_Item': 'Idade (anos)', 'Decisao': 'Decis√£o'},
                color='Decisao',
                color_discrete_sequence=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
            )
            st.plotly_chart(fig_idade, use_container_width=True)
        
        st.subheader("‚ö†Ô∏è Itens de Alta Prioridade")
        
        alta_similaridade = filtered_data[filtered_data['Similaridade_Num'] >= 70]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"**{len(alta_similaridade):,} itens** com similaridade ‚â• 70%")
            
            if len(alta_similaridade) > 0:
                top_regioes = alta_similaridade['Regiao'].value_counts().head()
                st.write("**Localiza√ß√µes com mais itens de alta similaridade:**")
                for localizacao, count in top_regioes.items():
                    st.write(f"‚Ä¢ {localizacao}: {count} itens")
        
        with col2:
            reclassificacao_imediata = filtered_data[filtered_data['Decisao'] == 'RECLASSIFICAR']
            st.warning(f"**{len(reclassificacao_imediata):,} itens** para reclassifica√ß√£o imediata")
            
            if len(reclassificacao_imediata) > 0:
                similaridade_media = reclassificacao_imediata['Similaridade_Num'].mean()
                st.write(f"**Similaridade m√©dia:** {similaridade_media:.1f}%")
                if 'Idade_Item' in reclassificacao_imediata.columns:
                    idade_media_reclas = reclassificacao_imediata['Idade_Item'].mean()
                    st.write(f"**Idade m√©dia:** {idade_media_reclas:.1f} anos")
    
    with tab3:
        st.subheader("An√°lise por Localiza√ß√£o")
        
        if not regional_analysis.empty:
            st.write("**Resumo por Localiza√ß√£o:**")
            
            regional_display = regional_analysis.copy()
            regional_display['Efici√™ncia_Reclassifica√ß√£o'] = (
                regional_display['Itens_Reclassificar'] / 
                filtered_data.groupby('Regiao').size()
            ) * 100
            
            regional_display = regional_display.round(2)
            regional_display.columns = ['Itens p/ Reclassificar', 'Similaridade M√©dia (%)', 'Efici√™ncia (%)']
            
            st.dataframe(regional_display.sort_values('Efici√™ncia (%)', ascending=False))
            
            fig = px.scatter(
                x=regional_display['Similaridade M√©dia (%)'],
                y=regional_display['Efici√™ncia (%)'],
                size=regional_display['Itens p/ Reclassificar'],
                hover_name=regional_display.index,
                title="Efici√™ncia por Localiza√ß√£o: Similaridade vs % Reclassifica√ß√£o",
                labels={
                    'x': 'Similaridade M√©dia (%)',
                    'y': 'Efici√™ncia na Reclassifica√ß√£o (%)'
                }
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.subheader("Dados e Exporta√ß√£o")
        
        # Diagn√≥stico de Idade
        with st.expander("üîç Diagn√≥stico de Idade dos Itens"):
            if 'Ano Incorpora√ß√£o' in filtered_data.columns and 'Idade_Item' in filtered_data.columns:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("Ano M√©dio de Incorpora√ß√£o", 
                             f"{filtered_data['Ano Incorpora√ß√£o'].mean():.0f}")
                    st.metric("Ano M√≠nimo", 
                             f"{filtered_data['Ano Incorpora√ß√£o'].min():.0f}")
                    st.metric("Ano M√°ximo", 
                             f"{filtered_data['Ano Incorpora√ß√£o'].max():.0f}")
                
                with col2:
                    st.metric("Idade M√©dia Calculada", 
                             f"{filtered_data['Idade_Item'].mean():.1f} anos")
                    st.metric("Idade M√≠nima", 
                             f"{filtered_data['Idade_Item'].min():.0f} anos")
                    st.metric("Idade M√°xima", 
                             f"{filtered_data['Idade_Item'].max():.0f} anos")
                
                with col3:
                    total_registros = len(filtered_data)
                    registros_com_data = filtered_data['Ano Incorpora√ß√£o'].notna().sum()
                    registros_sem_data = total_registros - registros_com_data
                    
                    st.metric("Total de Registros", f"{total_registros:,}")
                    st.metric("Com Data", f"{registros_com_data:,}")
                    st.metric("Sem Data", f"{registros_sem_data:,}", 
                             delta=f"{(registros_sem_data/total_registros*100):.1f}%" if total_registros > 0 else "0%")
                
                # Distribui√ß√£o por d√©cada
                st.write("**Distribui√ß√£o por D√©cada de Incorpora√ß√£o:**")
                filtered_data['Decada'] = (filtered_data['Ano Incorpora√ß√£o'] // 10 * 10).astype('Int64')
                decada_counts = filtered_data['Decada'].value_counts().sort_index()
                
                fig_decada = px.bar(
                    x=decada_counts.index.astype(str),
                    y=decada_counts.values,
                    title="Quantidade de Itens por D√©cada",
                    labels={'x': 'D√©cada', 'y': 'Quantidade de Itens'}
                )
                st.plotly_chart(fig_decada, use_container_width=True)
        
        st.write(f"**Mostrando {len(filtered_data):,} registros filtrados:**")
        
        show_columns = st.multiselect(
            "Selecione as colunas para exibir:",
            filtered_data.columns.tolist(),
            default=['Localiza√ß√£o', 'Invent√°rio', 'Denomina√ß√£o do Imobilizado', 'Item Consum√≠vel Similar', 'Decisao']
        )
        
        if show_columns:
            st.dataframe(filtered_data[show_columns])
        
        st.subheader("üíæ Exportar Dados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            csv = filtered_data.to_csv(index=False)
            st.download_button(
                label="üìÑ Baixar CSV",
                data=csv,
                file_name=f"patrimonio_filtrado_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        
        with col2:
            excel_data = export_to_excel(filtered_data)
            st.download_button(
                label="üìä Baixar Excel",
                data=excel_data,
                file_name=f"patrimonio_analise_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

if __name__ == "__main__":
    main()



